import datetime
import logging
import argparse
import os
import time
import subprocess
import shlex
import json

from pyutil.program.script import script_init

from pyutil.program.conf2 import Conf


script_init(['zhenghuabin', 'huanglong', 'xiaxuhong'], script_name='etcd_dump')
logger = logging.getLogger()


def sync_to_backup_cluster(dump_file):
    """
    sync the latest successfully dumped file to backup cluster
    :param dump_file:
    :return:
    """
    with open(dump_file) as fp:
        content = fp.read()
        obj = json.loads(content)
        if not obj:
            logger.error("dump file error, length=%d", len(content))
            return
    host = Conf('/opt/tiger/ss_conf/ss/etcd.conf').get_values('etcd_backup_host_port')[0]
    host = 'http://' + host
    cmd = "python cli.py --file %s restore %s" % (dump_file, host)
    logging.info(cmd)
    try:
        output = subprocess.check_output(shlex.split(cmd))
        logging.info(output)
    except subprocess.CalledProcessError as e:
        logging.exception("cmd: %s, returncode: %d, output: %s", e.cmd, e.returncode, e.output)


def main():
    parser = argparse.ArgumentParser(
        description='backup etcd cluster data periodically',
        version='1.0.0')
    parser.add_argument('--host',
                        dest='host',
                        default='10.4.21.12:4001',
                        help="etcd host")
    parser.add_argument('--backup_interval',
                        dest='interval',
                        type=float,
                        default='15',
                        help="backup interval in minutes")
    parser.add_argument('--backup_keep_days',
                        dest='keep_days',
                        type=int,
                        default='15',
                        help="how many days to keep backup")
    parser.add_argument('--backup_root_dir',
                        dest='backup_root',
                        default='/opt/etcd_dump',
                        help="where to store backup files")
    parser.add_argument('--debug',
                        action="store_true",
                        help="set log level to debug")
    args = parser.parse_args()
    host = "http://" + args.host
    backup_root = args.backup_root
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    logging.info('start ...')
    while True:
        now = datetime.datetime.now()
        logging.info('remove old backup')
        old_date = now - datetime.timedelta(days=args.keep_days)
        old_date_str = old_date.strftime('%Y%m%d')
        cmd = "rm -rf %s/backup/%s" % (backup_root, old_date_str)
        logging.info(cmd)
        os.system(cmd)

        logging.info('backup')
        date_str = now.strftime('%Y%m%d')
        cmd = 'mkdir -p %s/backup/%s' % (backup_root, date_str)
        os.system(cmd)
        datetime_str = now.strftime('%Y%m%d_%H%M%S')
        file_name = "%s/backup/%s/%s" % (backup_root, date_str, datetime_str)
        backup_cmd = "python cli.py --file %s dump %s" % (file_name, host)
        logging.info(backup_cmd)
        try:
            output = subprocess.check_output(shlex.split(backup_cmd))
            logging.info(output)
            sync_to_backup_cluster(file_name)
        except Exception as e:
            logging.exception(e)
        seconds = args.interval * 60
        logging.info('next backup will start at %s' % (now + datetime.timedelta(seconds=seconds)))
        time.sleep(seconds)


if __name__ == '__main__':
    main()




# coding=utf-8
from collections import Counter
import functools
import logging
import multiprocessing
import socket
import threading
import time
from collections import Counter, defaultdict

from pyutil.kafka import AckConsumer
from pyutil.kafka.consumer import MessageAcker
from pyutil.program import metrics, timing
from pyutil.program.fmtutil import fmt_exception
from pyutil.program.functool import keep_run
from pyutil.program.hash_utils import hash_uint64
from pyutil.program.keyed_worker_pool import KeyedWorkerPool
from pyutil.program.python import split_chunks
from pyutil.program.tracing import start_tracer, start_span, start_child_span, get_current_trace_id, get_current_span
from pyutil.kafka.pipeline.kafka_utils import get_kafka_partitions, get_redis_client, get_kafka_client

logger = logging

MAX_PENDING_TIMEOUT = 7200
CHECK_PENDING_INTERVAL = 180
DEFAULT_KAFKA_BATCH_SIZE = 2000

def _get_message_log_id(message):
    meta = message.meta
    return 'm=%s,%s,%s key=%s' % (meta.topic, meta.partition, meta.offset, message.message.key)

class KafkaPipeline(object):
    def __init__(self, name, conf, handle, worker_num, thread_num,
            kafka_topics, kafka_partitions, kafka_group,
            kafka_cluster, acker_cluster,
            kafka_batch_size=DEFAULT_KAFKA_BATCH_SIZE,
            batch_process=False,
            batch_size=0,
            hosts=None,
            host_partitions=None,
            worker_reload=None, worker_reload_interval=1,
            pool_partition_num=0,
            partition_worker_num=None, worker_thread_num=None,
            get_message_log_id=None,
            dry_run=False,
            message_format='json',
            pending_full_discard=False,
            process_per_partition=False,
            batch_by_default_key=False,
            ):
        '''
        :param str name: pipeline name
        :param callable handle: 若batch_process为True, 则handle(messages), 否则handle(message)
        :param int worker_num: worker num for each pool
        :param float partition_worker_num: worker num for each partition
        :param int worker_thread_num/thread_num: thread num for each worker.
        :param int pool_partition_num: partition num for each pool, 0 for all partitions
            pipeline_thread_num = pool_num * worker_num * thread_num
            pool_num = len(kafka_partitions) / pool_partition_num
        :param list kafka_topics:
            [
                dict(max_throughput=0, topics=['topic_urgent'], urgent=True),
                (0, ['topic1', 'topic2']), # (max_throughput, topics)
                (100, ['topic3', 'topic4']),
            ]
            or 'topic1'
            or ['topic1', 'topic2']
        :param list hosts: pipeline部署的机器列表, 用于推导host_partitions
        :param list host_partitions/kafka_partitions: pipeline在当前host消费的partitions
        :param str kafka_cluster: kafka cluster name
        :param int kafka_batch_size: 每次从kafka中获取的消息数
        :param str acker_cluster: redis acker cluster name, if None, acker does nothing
        :param bool batch_process: 是否批处理任务
        :param int batch_size: 批处理的message数, 0表示不限. 同一batch的messages的key必须相同
        :param callable worker_reload: worker周期性执行的函数
        :param int worker_reload_interval: 加载间隔(s)
        :param callable get_message_log_id: get_message_log_id(message)
        :param bool process_per_partition: 每个topic x partition对应一个producer process
        :param bool batch_by_default_key: 批处理对于不需要区分key（或者生产者没有传key）的情况使用默认key来获取batch
        
        kafka_partitions和hosts不能同时提供
        '''
        def conv_ktopic(t):
            if isinstance(t, (tuple, list)):
                t = dict(max_throughput=t[0], topics=t[1])
            return t

        timer = timing.Timer()
        if isinstance(kafka_topics, basestring):
            kafka_topics = [dict(topics=[kafka_topics])]
        elif all([isinstance(x, basestring) for x in kafka_topics]):
            kafka_topics = [dict(topics=kafka_topics)]
        else:
            kafka_topics = map(conv_ktopic, kafka_topics)

        if kafka_partitions:
            import warnings
            warnings.warn('kafka_partitions is deprecated, use host_partitions insteaed', DeprecationWarning)
        if worker_num or thread_num:
            import warnings
            warnings.warn('worker_num and thread_num is deprecated, use pool_worker_num and worker_thread_num instead', DeprecationWarning)
        host_partitions = host_partitions or kafka_partitions
        if host_partitions and hosts:
            raise ValueError('host_partitions and hosts can not be provided at the same time')
        host = socket.gethostname()
        if hosts and host not in hosts:
            raise ValueError('%s not in given hosts: %s' % (host, ','.join(hosts)))
        get_message_log_id = get_message_log_id or _get_message_log_id
        self.message_acker = MessageAcker(get_redis_client(conf, name=acker_cluster, dry_run=dry_run) if acker_cluster else None)
        handle_classs = BatchHandler if batch_process else Handler
        handler = handle_classs(handle, self.message_acker, name)
        timer.timing('misc')
        kafka_client = get_kafka_client(conf, kafka_cluster)
        self.topic_partitions = self._get_topic_partitions(kafka_client, kafka_topics)
        timer.timing('kafka_client')
        self.producers = []
        self.workers = []
        if hosts:
            host_partitions = get_kafka_partitions(hosts, len(self.topic_partitions))
        host_partitions = host_partitions or self.topic_partitions
        pool_partition_num = pool_partition_num or len(host_partitions)
        pool_worker_num = max(1, worker_num or int(partition_worker_num * pool_partition_num))
        worker_thread_num = worker_thread_num or thread_num

        list_of_partitions = split_chunks(pool_partition_num, host_partitions)
        n = len(list_of_partitions)
        for i, partitions in enumerate(list_of_partitions):
            if n == 1:
                pool_name = name
            elif pool_partition_num == 1:
                pool_name = '%s_p%s' % (name, partitions[0])
            else:
                pool_name = '%s%s' % (name, i)
            worker = KeyedWorkerPool(pool_name, handler.process,
                    worker_num=pool_worker_num,
                    thread_num=worker_thread_num,
                    post_fork_reload=worker_reload,
                    reload_interval=worker_reload_interval,
                    metric_name=name,
                    key_hash=hash_uint64, # 使用同kafka producer不同的hash函数, 避免分发不均匀
                    pending_full_discard=handler.discard if pending_full_discard else None,
                    )
            self.workers.append(worker)
            timer.timing('worker_pool')
            for ktopic in kafka_topics:
                max_throughput = ktopic.get('max_throughput', 0)
                topics = ktopic['topics']
                urgent = ktopic.get('urgent', False)
                producer_kwargs = dict(
                        conf=conf,
                        put_task=functools.partial(worker.put_task, urgent=urgent),
                        message_acker=self.message_acker,
                        kafka_topics=topics,
                        kafka_group=kafka_group,
                        kafka_partitions=partitions,
                        kafka_client=kafka_client,
                        max_throughput=max_throughput / float(n),
                        message_format=message_format,
                        kafka_batch_size=kafka_batch_size or DEFAULT_KAFKA_BATCH_SIZE,
                        batch_process=batch_process,
                        batch_size=batch_size,
                        batch_by_default_key=batch_by_default_key,
                        )
                if process_per_partition:
                    for partition in partitions:
                        producer = ReadKafkaTaskProducer(**dict(producer_kwargs,
                            kafka_partitions=[partition],
                            max_throughput=max_throughput / (len(partitions) * float(n)),
                            ))
                        producer_process = multiprocessing.Process(target=producer.run)
                        producer_process.daemon = True
                        self.producers.append(producer_process)
                else:
                    producer = ReadKafkaTaskProducer(**producer_kwargs)
                    producer_thread = threading.Thread(target=producer.run)
                    producer_thread.setDaemon(True)
                    self.producers.append(producer_thread)
            timer.timing('kafka_consumer')
        logger.info('pipeline %s constructed, partitions=%s-%s/%s partition_threads=%s*%s pool_partition_num=%s kafka_group=%s, dur(%s)', name,
                host_partitions[0], host_partitions[-1], len(self.topic_partitions),
                partition_worker_num, worker_thread_num, pool_partition_num,
                kafka_group,
                timer.pformat())

    def _get_topic_partitions(self, kafka_client, kafka_topics):
        first_topic = kafka_topics[0]['topics'][0]
        kafka_client.load_metadata_for_topics(first_topic)
        return kafka_client.topic_partitions[first_topic]

    def start(self):
        [x.start() for x in self.workers]
        start_tracer()
        [x.start() for x in self.producers]

class Handler(object):
    MAX_TRIES = 3
    message_tries = Counter()
    def __init__(self, handle, message_acker, pipeline_name):
        self.handle = handle
        self.message_acker = message_acker
        self.pipeline_name = pipeline_name
        self.metric_prefix = 'kafka_pipeline.%s' % pipeline_name
        self._define_metrics()

    def _define_metrics(self):
        metrics.define_counter('throughput', 'op', prefix=self.metric_prefix)
        metrics.define_timer('latency', 'ms', prefix=self.metric_prefix)
        metrics.define_tagkv('name', [self.pipeline_name])
        metrics.define_tagkv('tries', [str(i+1) for i in range(self.MAX_TRIES)])
        metrics.define_tagkv('status', ['ok', 'exception', 'fail_permanently', 'discard', 'discard_exception'])
        self.tagkv = dict(name=self.pipeline_name)


    def process(self, message):
        '''
        message - (meta(topic, group, partition, offset), message(key, value, ...), unpacked_value)
        '''
        meta = message.meta
        message_id = '%s,%s,%s' % (meta.topic, meta.partition, meta.offset)
        log_id = '[%s][trace=%s]' % (message_id, get_current_trace_id())
        tries = self.message_tries[message_id] + 1
        try:
            with metrics.Timer('latency', tagkv=self.tagkv, prefix=self.metric_prefix):
                self.handle(message)
            self.message_acker.ack_by_meta(meta)
            self.message_tries.pop(message_id, None)
            status = 'ok'
        except Exception as e:
            status = 'exception'
            with start_child_span(get_current_span(), 'pending_exception',
                                  tags=dict(msg=str(e), msg_id=message_id, will_ack=tries >= self.MAX_TRIES)):
                self.message_tries[message_id] = tries
                logger.exception('%s fail to handle message(tries=%s/%s): %s, key=%s',
                                 log_id, tries, self.MAX_TRIES, e, message.message.key)
                if tries >= self.MAX_TRIES:
                    status = 'fail_permanently'
                    logging.info('%s fail permanently after %s tries, key=%s', log_id, tries, message.message.key)
                    self.message_acker.ack_by_meta(meta)
                    self.message_tries.pop(message_id, None)
        finally:
            metrics.emit_counter('throughput', 1, prefix=self.metric_prefix,
                    tagkv=dict(self.tagkv, status=status, tries=str(tries)))


    def discard(self, message):
        '''
        message - (meta(topic, group, partition, offset), message(key, value, ...), unpacked_value)
        '''
        meta = message.meta
        message_id = '%s,%s,%s' % (meta.topic, meta.partition, meta.offset)
        tries = self.message_tries[message_id] + 1
        try:
            self.message_acker.ack_by_meta(meta)
            self.message_tries.pop(message_id, None)
            logging.info('Discard message %s, key=%s trace=%s',  message_id, message.message.key, get_current_trace_id())
            status = 'discard'
        except Exception as e:
            status = 'discard_exception'
            self.message_tries[message_id] = tries
            logger.exception('Fail to discard message %s, key=%s: %s, trace=%s',
                    message_id, message.message.key, e, get_current_trace_id())
        finally:
            metrics.emit_counter('throughput', 1, prefix=self.metric_prefix,
                    tagkv=dict(self.tagkv, status=status, tries=str(tries)))

class BatchHandler(Handler):

    def process(self, messages):
        '''
        message - (meta(topic, group, partition, offset), message(key, value, ...), unpacked_value)
        '''
        tries = 1
        try:
            with metrics.Timer('latency', tagkv=self.tagkv, prefix=self.metric_prefix):
                self.handle(messages)
            for m in messages:
                self.message_acker.ack_by_meta(m.meta)
            status = 'ok'
        except Exception as e:
            status = 'exception'
            message = messages[0]
            meta = message.meta
            message_id = '%s,%s,%s' % (meta.topic, meta.partition, meta.offset)
            with start_child_span(get_current_span(), 'pending_exception', tags=dict(msg=str(e), msg_id=message_id)):
                logger.exception('[%s] fail to handle %s messages: %s, key=%s',
                                 message_id, len(messages), e, message.message.key)
        finally:
            metrics.emit_counter('throughput', 1, prefix=self.metric_prefix,
                    tagkv=dict(self.tagkv, status=status, tries=str(tries)))

    def discard(self, messages):
        '''
        message - (meta(topic, group, partition, offset), message(key, value, ...), unpacked_value)
        '''
        message = messages[0]
        meta = message.meta
        message_id = '%s,%s,%s' % (meta.topic, meta.partition, meta.offset)
        log_id = '[%s][trace=%s]' % (message_id, get_current_trace_id())
        tries = 1
        try:
            for m in messages:
                self.message_acker.ack_by_meta(m.meta)
            logging.info('%s discard %s messages, key=%s', log_id,
                    len(messages), message.message.key)
            status = 'discard'
        except Exception as e:
            status = 'discard_exception'
            logger.exception('%s fail to discard %s messages: %s, key=%s', log_id,
                    len(messages), e, message.message.key)
        finally:
            metrics.emit_counter('throughput', 1, prefix=self.metric_prefix,
                    tagkv=dict(self.tagkv, status=status, tries=str(tries)))

class ReadKafkaTaskProducer(object):
    def __init__(self, conf, put_task, message_acker, kafka_topics, kafka_group,
                 kafka_partitions, get_message_log_id=_get_message_log_id,
                 cluster_name=None, kafka_client=None, max_throughput=0, message_format='json',
                 kafka_batch_size=DEFAULT_KAFKA_BATCH_SIZE, batch_process=False, batch_size=0, batch_by_default_key=False,
                 *args, **kwargs):
        '''
        :param kafka_client:
        :param str cluster_name: kafka cluster name. kafka_client和cluster_name必须给一个，优先使用kafka_client
        :param callable put_task: put_task(task_key, task, task_log_id)
        :param list kafka_topics:
        :param int kafka_batch_size: see KafkaPipeline
        :param bool batch_process: see KafkaPipeline
        :param int batch_size: see KafkaPipeline
        :param bool batch_by_default_key: see KafkaPipeline
        '''
        if not cluster_name and not kafka_client:
            raise ValueError('cluster_name or kafka_client must be provided')
        self.conf = conf
        self.put_task = put_task
        self._get_message_log_id = get_message_log_id
        self.kafka_topics = kafka_topics
        self.kafka_group = kafka_group
        self.kafka_partitions = kafka_partitions
        self.max_throughput = max_throughput
        self.message_format = message_format
        self.batch_process = batch_process
        self.batch_size = batch_size
        self.batch_by_default_key = batch_by_default_key
        self.kafka_batch_size = kafka_batch_size
        self._message_counter = 0
        if not kafka_client:
            kafka_client = get_kafka_client(conf, cluster_name)
        self._kafka_consumers = []

        for ktopic in kafka_topics:
            partitions = self.kafka_partitions[ktopic] if type(self.kafka_partitions) == dict else self.kafka_partitions
            kafka_consumer = AckConsumer(message_acker, kafka_client,
                                         self.kafka_group, ktopic,
                                         partitions=partitions, transform_message=True,
                                         message_format=message_format,
            )
            self._kafka_consumers.append(kafka_consumer)


    @keep_run(30)
    def run(self):
        logging.info('start task producer, topics=%s, partitions=%s',
                self.kafka_topics, self.kafka_partitions)
        last_pend_ts = 0
        pending_timeout = 0
        while True:
            try:
                with start_span('producer_root') as span:
                    last_pend_ts, pending_timeout = self._run_once(span, last_pend_ts, pending_timeout)
            except Exception as e:
                logging.exception('unexpected: %s', fmt_exception(e))
                with start_span('producer_exception_sleep'):
                    time.sleep(30)

    def _run_once(self, span, last_pend_ts, pending_timeout):
        timer = timing.Timer()
        counts = Counter()
        message_count = 0
        now_ts = time.time()
        check_pending = now_ts - last_pend_ts > CHECK_PENDING_INTERVAL
        quota = self.kafka_batch_size
        for kconsumer in self._kafka_consumers:
            tags = dict(topic=kconsumer.topic)
            try:
                if check_pending:
                    with start_child_span(span, 'producer_get_pending', tags=tags):
                        messages = kconsumer.get_pending_messages(
                                count=20000, buffer_size=512000,
                                timeout=pending_timeout)
                else:
                    with start_child_span(span, 'producer_get_messages', tags=tags):
                        messages = kconsumer.get_messages(count=quota, timeout=.2)
                timer.timing('get')
                if messages:
                    with start_child_span(span, 'producer_put_messages', tags=dict(tags, count=str(len(messages)))):
                        self._put_messages(messages)
                timer.timing('put_queue')
                counts[kconsumer.topic] = len(messages)
                message_count += len(messages)
                quota -= len(messages)
                if quota <= 0:
                    break
            except Exception as e:
                logging.exception('fail to get message from %s: %s', kconsumer.topic, e)
        if check_pending:
            last_pend_ts = now_ts
            pending_timeout = MAX_PENDING_TIMEOUT
        logging.info('got %s %smessages: %s, dur(%s), topics=%s, partitions=%s', message_count,
                'pending ' if check_pending else '',
                ' '.join('%s=%s' % (k, v) for k, v in counts.items() if v),
                timer.pformat(),
                self.kafka_topics,
                self.kafka_partitions,
                )
        if not message_count:
            with start_child_span(span, 'producer_empty_sleep'):
                time.sleep(1)
        return last_pend_ts, pending_timeout

    def _put_messages(self, messages):
        def add_count(count):
            self._message_counter += count
            if self.max_throughput >= 1:
                if self._message_counter % self.max_throughput == 0:
                    time.sleep(1)
            elif self.max_throughput:
                time.sleep(1 / self.max_throughput)

        key2msgs = defaultdict(list)
        for message in messages:
            if self.batch_process and self.batch_by_default_key:
                key = 'default_key'
            elif message.message.key is not None:
                key = message.message.key
            else:
                key = message.message.value

            if self.batch_process:
                key2msgs[key].append(message)
            else:
                self.put_task(key, message, self._get_message_log_id(message))
                add_count(1)
        if self.batch_process:
            for key, msgs in key2msgs.items():
                list_of_msgs = split_chunks(self.batch_size or len(msgs), msgs)
                for msgs_ in list_of_msgs:
                    if self.batch_by_default_key:
                        #防止put_task集中到一个worker， 使用msgs第一个元素的value作为key将task打散
                        self.put_task(msgs_[0].message.value, msgs_, self._get_message_log_id(msgs_[0]))
                    else:
                        self.put_task(key, msgs_, self._get_message_log_id(msgs_[0]))
                    add_count(len(msgs_))

    def seek_to_latest(self):
        for kconsumer in self._kafka_consumers:
            kconsumer.seek(0, 2)




def test_kafka_handler(message):
    meta = message.meta
    message_id = message.message_id
    sender = message.unpacked_value.get('event_sender') or 'unknown'
    uv = message.unpacked_value
    print message_id, sender, meta, uv
    time.sleep(1)

def test_kafka_pipeline(conf):
    from pyutil.kafka.pipeline.kafka_pipeline import KafkaPipeline
    pipeline = KafkaPipeline(
        'kafka_pipeline_test', conf, test_kafka_handler, 1, 1,
        ['comment_action_log'], None, 'kafka_pipeline_jun',
        'kafka_misc', 'redis_crawl_acker',
        kafka_batch_size=10,
        batch_process=False,
        batch_size=0,
        hosts=None,
        host_partitions=None,
        worker_reload=None, worker_reload_interval=10,
        pool_partition_num=0,
        partition_worker_num=None, worker_thread_num=None,
        get_message_log_id=None,
        dry_run=False,
        message_format='json',
        pending_full_discard=False,
        process_per_partition=False,
    )
    pipeline.start()
    while True:
        time.sleep(100)

if __name__ == '__main__':
    from pyutil.program.conf import Conf
    # conf = Conf("/opt/tiger/ss_conf/ss/redis.conf")
    # test_kafka_pipeline(conf)
#coding=utf-8
import os
import time
import types
from mock import Mock
from pyutil.program import metrics
from pyutil.redis.redis_proxy import make_redis_proxy_cli
from kafka import KafkaClient

def partition_by_host(hosts, partition_num):
    '''
    >>> partition_by_host(['in20-160','in20-161','in20-162','in27-198','in27-199','in27-200'], 20)
    {'in27-200': [17, 18, 19], 'in27-199': [14, 15, 16], 'in27-198': [11, 12, 13], 'in20-162': [8, 9, 10], 'in20-161': [4, 5, 6, 7], 'in20-160': [0, 1, 2, 3]}
    '''
    from pyutil.program.python import split_chunks_evenly
    host2partitions = {}
    for i, ps in enumerate(split_chunks_evenly(len(hosts), range(partition_num), padding=True)):
        host2partitions[hosts[i]] = ps
    return host2partitions

def get_kafka_partitions(hosts, partition_num):
    import socket
    hostname = socket.gethostname()
    host2partitions = partition_by_host(hosts, partition_num)
    return host2partitions.get(hostname)


def get_kafka_client(conf, cluster_name):
    return KafkaClient(get_kafka_broker_list(conf, cluster_name))

def get_kafka_broker_list(conf, cluster_name):
    valid_cluster = conf.get_values("valid_cluster")
    if cluster_name not in valid_cluster:
        raise ValueError("not support cluster name %s" % cluster_name)
    broker_list = conf.get_values(cluster_name)
    if not broker_list:
        raise ValueError("no available kafka broker found.")
    return ','.join(broker_list)


REDIS_SUPPORTED_COMMANDS = set([
        'del', 'delete', 'expire',

        'set', 'setnx', 'setex', 'getset', 'incr', 'decr', 'incrby', 'decrby',
        'append',
        'mset',
        'get', 'mget', 'exists',

        'hset', 'hmset', 'hdel', 'hincrby', 'hincrbyfloat',
        'hget', 'hmget', 'hexists', 'hlen', 'hgetall', 'hkeys', 'hvals',

        'zadd', 'zincrby', 'zrem', 'zremrangebyrank', 'zremrangebyscore',
        'zcard', 'zcount', 'zscore', 'zrank', 'zrevrank',
        'zrange', 'zrangebyscore', 'zrevrange', 'zrevrangebyscore',

        'lpush', 'rpush', 'lpop', 'rpop',
        'llen', 'lindex', 'lrange',
        ])

def get_redis_client(conf, name, socket_timeout=10, strict_redis=True, dry_run=False):
    def define_metrics(prefix, caller):
        metrics.define_counter('throughput', 'op', prefix=prefix)
        metrics.define_counter('throughput.exception', 'op', prefix=prefix)
        metrics.define_timer('latency', 'us', prefix=prefix)
        metrics.define_tagkv('caller', [caller])
        metrics.define_tagkv('cluster', [name])
        metrics.define_tagkv('cmd', list(REDIS_SUPPORTED_COMMANDS) + ['unsupported'])

    def new_execute_command(self, *args, **options):
        cmd = args[0].lower()
        tagkv = dict(
                caller=caller,
                cluster=name,
                cmd=cmd if cmd in REDIS_SUPPORTED_COMMANDS else 'unsupported',
                )
        ts = time.time()
        try:
            return old_execute_command(*args, **options)
        except:
            metrics.emit_counter('throughput.exception', 1, prefix=prefix, tagkv=tagkv)
        finally:
            metrics.emit_counter('throughput', 1, prefix=prefix, tagkv=tagkv)
            metrics.emit_timer('latency', (time.time() - ts) * 1000000, prefix=prefix, tagkv=tagkv)
    caller = os.environ.get('SCRIPT_NAME') or 'unknown'
    prefix = 'kafkapipeline.redisclient'
    define_metrics(prefix, caller)
    servers = conf.get_values(name)
    redis_client = make_redis_proxy_cli(servers, socket_timeout=socket_timeout, strict_redis=strict_redis)
    old_execute_command = redis_client.execute_command
    redis_client.execute_command = types.MethodType(new_execute_command, redis_client)
    if dry_run:
        for k in ['set', 'setex', 'zadd', 'zrem']:
            setattr(redis_client, k, Mock())
    return redis_client

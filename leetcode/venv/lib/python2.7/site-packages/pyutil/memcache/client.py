# -*- coding: utf-8 -*-
import sys, time, logging, threading, memcache

import pyutil.program.metrics2 as metrics

from hash_ring.memcache_ring import MemcacheRing
from memcache_proxy import MemcacheProxy


class MemcacheClient(object):
    _METRIC_PREFIX = 'inf.memcacheclient'
    _enable_reuse_client = False # TODO: disable it temporalily
    _saved_client = {}
    _lock_saved_client = threading.Lock()
    _servers_to_cluster_mapping = None
    _clusters_conf = None
    _enable_metrics = True
    _metrics_defined = False

    @staticmethod
    def get_servers(cluster):
        from pyutil.program.conf import Conf
        conf = Conf('/opt/tiger/ss_conf/ss/memcache.conf')
        res = {}
        for suffix in ['lf', 'hy']:
            v = conf.get('_'.join([cluster, suffix]))
            if v != '':
                res[suffix] = [x.strip() for x in v.split(',')]
        if len(res) == 0:
            v = conf.get(cluster)
            if v != '':
                res['hy'] = [x.strip() for x in v.split(',')]
        return res

    # only get the local datacenter servers
    @staticmethod
    def get_cluster_servers(cluster, bypass_cache=False):
        from pyutil.program.conf import Conf
        conf = Conf('/opt/tiger/ss_conf/ss/memcache.conf', bypass_cache=bypass_cache)
        servers = conf.get_values(cluster)
        return servers

    @staticmethod
    def is_auto_conf_disabled(cluster, bypass_cache=True):
        from pyutil.program.conf import Conf
        conf = Conf('/opt/tiger/ss_conf/ss/cache_auto_conf.conf', bypass_cache=bypass_cache)
        key = cluster + "_disable_auto"
        if conf.get(key):
            return True
        return False

    @staticmethod
    def get_or_create_client(memcache_servers, hash_ring, use_proxy, **kwargs):
        # sign的计算需要考虑所有影响到client创建的参数
        if MemcacheClient._enable_reuse_client:
            sign = unicode((memcache_servers, hash_ring, use_proxy, kwargs))
            with MemcacheClient._lock_saved_client:
                if sign in MemcacheClient._saved_client:
                    mc = MemcacheClient._saved_client[sign]
                    return mc, True
                else:
                    mc = MemcacheClient._create_client(memcache_servers, hash_ring, use_proxy, **kwargs)
                    MemcacheClient._saved_client[sign] = mc
                    return mc, False
        else:
            mc = MemcacheClient._create_client(memcache_servers, hash_ring, use_proxy, **kwargs)
            return mc, False

    @staticmethod
    def _create_client(memcache_servers, hash_ring, use_proxy, **kwargs):
        if use_proxy:
            return MemcacheProxy(memcache_servers, logging=1, **kwargs)
        elif hash_ring:
            return MemcacheRing(memcache_servers, logging=1, **kwargs)
        else:
            return memcache.Client(memcache_servers, logging=1, **kwargs)

    @staticmethod
    def clear_saved_client():
        '''
        Only used for debuging or testing.
        '''
        MemcacheClient._saved_client.clear()

    @staticmethod
    def detect_cluster(memcache_servers):
        '''workaround to get cluster'''
        if MemcacheClient._servers_to_cluster_mapping is None:
            # scan it for the first time
            MemcacheClient._servers_to_cluster_mapping = {}
            try:
                from pyutil.program.conf import Conf
                conf = Conf('/opt/tiger/ss_conf/ss/memcache.conf')
                for cluster in conf.get_all().keys():
                    servers = conf.get_values(cluster)
                    key = MemcacheClient.__make_key(servers)
                    MemcacheClient._servers_to_cluster_mapping[key] = cluster
            except ImportError as e:
                logging.exception(e)

        key = MemcacheClient.__make_key(memcache_servers)
        if key in MemcacheClient._servers_to_cluster_mapping:
            return MemcacheClient._servers_to_cluster_mapping[key]
        else:
            logging.error("Cluster not find.")
            return None

    @staticmethod
    def detect_use_proxy_or_not(cluster):
        if MemcacheClient._clusters_conf is None:
            # scan it for the first time
            MemcacheClient._clusters_conf = {}
            try:
                from pyutil.program.conf import Conf
                CONF_PATH = '/opt/tiger/ss_conf/ss/memcache.conf'
                conf = Conf(CONF_PATH)
                for k in conf.get_all().keys():
                    if k.endswith('_use_proxy'):
                        c = k[:-len('_use_proxy')]
                        MemcacheClient._clusters_conf[c] = {'use_proxy': conf.get(k)}
            except ImportError:
                pass

        if (cluster in MemcacheClient._clusters_conf
                and str(MemcacheClient._clusters_conf[cluster].get('use_proxy', '0')) == '1'):
            return True
        else:
            return False

    @staticmethod
    def __make_key(host_list):
        s_sorted = sorted(host_list)
        return unicode('_'.join(s_sorted))

    @staticmethod
    def define_metrics(cluster):
        metrics.define_tagkv('cluster', [cluster])

        if not MemcacheClient._enable_metrics or MemcacheClient._metrics_defined:
            return

        metrics.define_counter('count', prefix=MemcacheClient._METRIC_PREFIX)
        metrics.define_timer('latency', prefix=MemcacheClient._METRIC_PREFIX)
        metrics.define_counter('bytes_written', prefix=MemcacheClient._METRIC_PREFIX)
        metrics.define_counter('bytes_read', prefix=MemcacheClient._METRIC_PREFIX)
        metrics.define_counter('fail', prefix=MemcacheClient._METRIC_PREFIX)
        metrics.define_counter('hits', prefix=MemcacheClient._METRIC_PREFIX)
        metrics.define_counter('misses', prefix=MemcacheClient._METRIC_PREFIX)
        metrics.define_timer('batch_num', prefix=MemcacheClient._METRIC_PREFIX) # need percentile
        metrics.define_counter('split_count', prefix=MemcacheClient._METRIC_PREFIX)
        metrics.define_counter('deprecated_use', prefix=MemcacheClient._METRIC_PREFIX)

        metrics.define_tagkv('cmd', ['init', 'get', 'mget', 'set', 'mset', 'add', 'append', 'delete',
                                     'replace', 'prepend', 'cas', 'gets', 'incr', 'decr'])


    ''''''

    def __init__(self, memcache_servers=None, key_tmpl=None, timeout=900, client=None,
                 cpp_server_hash=True, hash_ring=False, prefix=None, use_proxy=False, socket_timeout=0.25,
                 stats_interval=None, failure_limit=10, cluster_name=None, conf_interval=60, auto_conf=False, **kwargs):
        '''
        @param memcache_servers: a list. e.g. ['10.4.18.70:5084', '10.4.18.71:5084'].
        @param timeout: in seconds. Actually it's the value's expiration time in memcached.
        @param socket_timeout: in seconds. It's socket timeout.
        @param client: deprecated
        @param stats_interval: deprecated
        '''

        ts = time.time()
        if cluster_name != None:
            self.cluster = cluster_name
            memcache_servers = MemcacheClient.get_cluster_servers(self.cluster)
        else:
            self.cluster = MemcacheClient.detect_cluster(memcache_servers)
        if not self.cluster:
            self.cluster = 'default'

        if memcache_servers is None or len(memcache_servers) == 0 or memcache_servers[0].split(":") == 0:
            raise ValueError("Can't get mc servers.")

        # TODO check memcache_servers len, or throw exception?

        if use_proxy or MemcacheClient.detect_use_proxy_or_not(self.cluster):
            # will ignore hash_ring (and server_hash)
            self.use_proxy = True
            hash_ring = False
        else:
            self.use_proxy = False

        self.hash_ring = hash_ring
        self.auto_conf = auto_conf
        self.key_tmpl = key_tmpl
        self.timeout = timeout
        self.prefix = prefix
        self.failure_limit = failure_limit
        self.socket_timeout = socket_timeout
        self.kwargs = kwargs
        self.conf_interval = conf_interval
        self.servers = memcache_servers

        # deprecated usage
        if not client:
            self.client, self.reuse_client = MemcacheClient.get_or_create_client(
                    memcache_servers, hash_ring, self.use_proxy,
                    socket_timeout=socket_timeout, failure_limit=failure_limit, **kwargs)
        else:
            logging.error('Deprecated: MemcacheClient init with a client from outside')
            self.reuse_client = True
            self.client = client

        exe_info = sys.version.lower()
        if exe_info.find('pypy') == -1:
            from jenkins import oneatatime
            self.server_hash = oneatatime if cpp_server_hash else memcache.serverHashFunction
        else:
            from jhash import oneatatimehash
            self.server_hash = oneatatimehash if cpp_server_hash else memcache.serverHashFunction

        MemcacheClient.define_metrics(self.cluster)
        if self.auto_conf:
            if not self.use_proxy:
                raise ValueError("Auto conf client don't support no proxy memcache cluster.")
            self.update_conf_thread = threading.Thread(target=self.update_server_conf)
            self.update_conf_thread.setDaemon(True)
            self.update_conf_thread.start()
        #logging.debug('MemcacheClient init. cluster=%s servers=%r prefix=%s key_tmpl=%s '
            #'timeout(exptime)=%d socket_timeout=%.3f reuse_client=%d '
            #'server_hash=%r hash_ring=%d use_proxy=%d failure_limit=%d init_cost=%.3fms'
            #% (self.cluster, memcache_servers, self.prefix, self.key_tmpl,
            #self.timeout, socket_timeout, self.reuse_client,
            #self.server_hash, hash_ring, self.use_proxy, failure_limit,
            #(time.time() - ts) * 1000))

        self._add_init_metrics(time.time() - ts)

    def make_key(self, key, key_tmpl=None):
        if key_tmpl:
            key = key_tmpl % key
        elif self.key_tmpl:
            key = self.key_tmpl % key
        if self.prefix:
            return "[%s]%s" % (self.prefix, str(key)) 
        else:
            return str(key)

    def update_server_conf(self):
        while True:
            time.sleep(self.conf_interval)
            try:
                if MemcacheClient.is_auto_conf_disabled(self.cluster):
                    continue
                servers = self.get_cluster_servers(self.cluster, bypass_cache=True)
                if servers != self.servers:
                    logging.debug("Find diff, start update server conf.")
                    self.servers = servers
                    client, self.reuse_client = MemcacheClient.get_or_create_client(self.servers, False, True, **self.kwargs)
                    self.client = client
            except Exception as e:
                logging.exception(e)

    def get(self, key, key_tmpl=None):
        ts = time.time()

        key = self.make_key(key, key_tmpl)
        result = self.client.get((self.server_hash(key), key))

        self._add_call_metrics('get', time.time() - ts, None)
        self._add_hit_miss_metrics('get', 1 if result != None else 0, 1 if result == None else 0)
        return result

    def set(self, key, val, timeout=None, key_tmpl=None):
        ts = time.time()

        key = self.make_key(key, key_tmpl)
        result = self.client.set((self.server_hash(key), key), val, timeout if timeout else self.timeout)

        self._add_call_metrics('set', time.time() - ts, result != 0)
        return result

    def add(self, key, val, timeout=None, key_tmpl=None):
        ts = time.time()

        key = self.make_key(key, key_tmpl)
        result = self.client.add((self.server_hash(key), key), val, timeout if timeout else self.timeout)

        self._add_call_metrics('add', time.time() - ts, result != 0)
        return result

    def append(self, key, val, key_tmpl=None):
        ts = time.time()

        key = self.make_key(key, key_tmpl)
        result = self.client.append((self.server_hash(key), key), val)

        self._add_call_metrics('append', time.time() - ts, result != 0)
        return result

    def delete(self, key, key_tmpl=None):
        ts = time.time()

        key = self.make_key(key, key_tmpl)
        result = self.client.delete((self.server_hash(key), key))

        self._add_call_metrics('delete', time.time() - ts, result != 0)
        return result

    def _mset(self, mapping, timeout=None, key_tmpl=None):
        ts = time.time()

        key_map = {key: self.make_key(key, key_tmpl) for key in mapping.iterkeys()}
        reverse_key_map = {v: k for k, v in key_map.iteritems()}
        notset_keys = self.client.set_multi(
            {(self.server_hash(key_map[key]), key_map[key]): val for key, val in mapping.iteritems()},
            timeout if timeout else self.timeout)

        self._add_call_metrics('mset', time.time() - ts, len(notset_keys) == 0)
        return [reverse_key_map[key[1]] for key in notset_keys]

    def mset(self, mapping, timeout=None, key_tmpl=None, split_num=1024):
        '''
        Sets multiple keys.

            >>> notset_keys = mc.mset({'key1' : 'val1', 'key2' : 'val2'})
            >>> len(notset_keys) == 0
            True

        @return: List of keys which failed to be stored
        '''

        split_count = 0
        final = [] # keys failed to be stored
        if len(mapping) <= split_num:
            final = self._mset(mapping, timeout, key_tmpl)
        else:
            def push_result(result):
                if isinstance(result, list):
                    for k in result:
                        final.append(k)

            sending = {}
            for key, value in mapping.items():
                sending[key] = value
                if len(sending) >= split_num:
                    push_result(self._mset(sending, timeout, key_tmpl))
                    split_count += 1
                    sending.clear()
            if len(sending):
                push_result(self._mset(sending, timeout, key_tmpl))
                split_count += 1

        self._add_batch_num_metrics('mset', len(mapping), split_count)
        return final

    def set_multi(self, mapping, timeout=None, key_tmpl=None, split_num=1024):
        return self.mset(mapping, timeout, key_tmpl, split_num)

    
    def get_multi(self, keys, key_tmpl=None, split_num=1024):
        return self.mget(keys, key_tmpl, split_num)


    def _mget(self, keys, key_tmpl=None):
        ts = time.time()

        key_map = {key: self.make_key(key, key_tmpl) for key in keys}
        reverse_key_map = {v: k for k, v in key_map.iteritems()}
        mapping = self.client.get_multi(
            [(self.server_hash(key_map[key]), key_map[key]) for key in keys])
        result = {reverse_key_map[key[1]]: val for key, val in mapping.iteritems()}

        self._add_call_metrics('mget', time.time() - ts, None)
        return result

    def mget(self, keys, key_tmpl=None, split_num=1024):
        split_count = 0
        final = {}
        if len(keys) <= split_num:
            final = self._mget(keys, key_tmpl)
        else:
            def push_result(result):
                if isinstance(result, dict):
                    for k, v in result.items():
                        final[k] = v

            sending = []
            for key in keys:
                sending.append(key)
                if len(sending) >= split_num:
                    push_result(self._mget(sending, key_tmpl))
                    split_count += 1
                    sending = []
            if len(sending):
                push_result(self._mget(sending, key_tmpl))
                split_count += 1

        self._add_hit_miss_metrics('mget', len(final), len(keys) - len(final))
        self._add_batch_num_metrics('mget', len(keys), split_count)
        return final

    def _len(self, data):
        if isinstance(data, basestring):
            return len(data)
        elif isinstance(data, (list, tuple)):
            l = 0
            for v in data:
                l += self._len(v)
            return l
        elif isinstance(data, dict):
            l = 0
            for k, v in data.items():
                l += self._len(k) + self._len(v)
            return l
        elif data is None or data is True or data is False:
            return 0
        elif isinstance(data, (int, float, long)):
            return len(str(data))
        else:
            return 0

    def _add_init_metrics(self, latency):
        self._add_call_metrics('init', latency, 1, 0, 0)

    def _add_call_metrics(self, cmd, latency, is_ok, bytes_written=0, bytes_read=0):
        ''' currently, not all commands pass in bytes_written and bytes_read '''

        if not MemcacheClient._enable_metrics:
            return
        tags = {'cluster': self.cluster, 'cmd': cmd}

        metrics.emit_counter('count', 1, self._METRIC_PREFIX, tags)
        metrics.emit_timer('latency', latency * 1000000, self._METRIC_PREFIX, tags)
        if is_ok is not None and is_ok is False:
            metrics.emit_counter('fail', 1, self._METRIC_PREFIX, tags)
        if bytes_written > 0:
            metrics.emit_counter('bytes_written', bytes_written, self._METRIC_PREFIX, tags)
        if bytes_read > 0:
            metrics.emit_counter('bytes_read', bytes_read, self._METRIC_PREFIX, tags)

    def _add_hit_miss_metrics(self, cmd, hits, misses):
        if not MemcacheClient._enable_metrics:
            return
        tags = {'cluster': self.cluster, 'cmd': cmd}
        if hits > 0:
            metrics.emit_counter('hits', hits, self._METRIC_PREFIX, tags)
        if misses > 0:
            metrics.emit_counter('misses', misses, self._METRIC_PREFIX, tags)

    def _add_batch_num_metrics(self, cmd, batch_num, split_count):
        if not MemcacheClient._enable_metrics:
            return
        tags = {'cluster': self.cluster, 'cmd': cmd}
        metrics.emit_timer('batch_num', batch_num, self._METRIC_PREFIX, tags)
        if split_count > 0:
            metrics.emit_counter('split_count', split_count, self._METRIC_PREFIX, tags)

    def replace(self, key, val, timeout=0, key_tmpl=None):
        ts = time.time()
        key = self.make_key(key, key_tmpl)
        result = self.client.replace((self.server_hash(key), key), val, timeout if timeout else self.timeout)
        self._add_call_metrics('replace', time.time() - ts, result != 0)
        return result

    def prepend(self, key, val, timeout=0, key_tmpl=None):
        ts = time.time()
        key = self.make_key(key, key_tmpl)
        result = self.client.prepend((self.server_hash(key), key), val, timeout if timeout else self.timeout)
        self._add_call_metrics('prepend', time.time() - ts, result != 0)
        return result

    def cas(self, key, val, timeout=0, key_tmpl=None):
        ts = time.time()
        key = self.make_key(key, key_tmpl)
        result = self.client.cas((self.server_hash(key), key), val, timeout if timeout else self.timeout)
        self._add_call_metrics('cas', time.time() - ts, result != 0)
        return result

    def reset_cas(self):
        self.client.reset_cas()

    def gets(self, key, key_tmpl=None):
        ts = time.time()
        key = self.make_key(key, key_tmpl)
        result = self.client.gets((self.server_hash(key), key))
        self._add_call_metrics('gets', time.time() - ts, None)
        self._add_hit_miss_metrics('gets', 1 if result != None else 0, 1 if result == None else 0)
        return result

    def incr(self, key, delta=1, key_tmpl=None):
        ts = time.time()
        key = self.make_key(key, key_tmpl)
        result = self.client.incr((self.server_hash(key), key), delta)
        self._add_call_metrics('incr', time.time() - ts, None)
        return result

    def decr(self, key, delta=1, key_tmpl=None):
        ts = time.time()
        key = self.make_key(key, key_tmpl)
        result = self.client.decr((self.server_hash(key), key), delta)
        self._add_call_metrics('decr', time.time() - ts, None)
        return result

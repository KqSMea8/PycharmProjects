#!/usr/bin/env python
# coding: utf-8
__author__ = 'zhenghuabin'

from pyutil.program import metrics2 as metrics

_THROUGHPUT= "throughput"
_ERROR = "error"
_LATENCY = "latency"
_BYTES_WRITTEN = "bytes_written"
_BYTES_READ = "bytes_read"
_HIT = "hit.throughput"
_MISS = "miss.throughput"
_BATCH_NUM = "batch_num"
_SPLIT_COUNT= "split_count"

class CacheMetrics(object):
    def __init__(self, cluster, prefix, psm=None):
        self.cluster = cluster
        self.prefix = prefix
        self.psm = psm
        if not psm:
            self.psm = 'nosql.psm.none'
        metrics.define_tagkv('cluster', [cluster])
        metrics.define_tagkv('caller', [self.psm])
        metrics.define_tagkv('lang', ['py'])

        metrics.define_counter(_BYTES_WRITTEN, prefix=prefix)
        metrics.define_counter(_BYTES_READ, prefix=prefix)

        metrics.define_timer(_BATCH_NUM, prefix=prefix)  # need percentile
        metrics.define_counter(_SPLIT_COUNT, prefix=prefix)

        metrics.define_counter(_HIT, prefix=self.prefix)
        metrics.define_counter(_MISS, prefix=self.prefix)

        metrics.define_counter(_THROUGHPUT, prefix=self.prefix)
        metrics.define_counter(_ERROR, prefix=self.prefix)
        metrics.define_timer(_LATENCY, prefix=self.prefix)

    @staticmethod
    def add_tagkv(key, tags):
        metrics.define_tagkv(key, tags)

    def get_tags(self, cmd, backend=None):
        cmd = cmd.upper()
        metrics.define_tagkv('cmd', [cmd])
        tags = {'cluster': self.cluster, 'caller': self.psm, 'cmd': cmd, 'lang': 'py'}
        if backend:
            metrics.define_tagkv('backend', [backend])
            tags['backend'] = backend
        return tags

    def add_init_metrics(self, latency):
        self.add_call_metrics('init', latency, 1, 0, 0)

    def add_call_metrics(self, cmd, latency, is_ok, bytes_written=0, bytes_read=0, backend=None):
        tags = self.get_tags(cmd, backend)
        latency *= 1000000
        if is_ok:
            metrics.emit_counter(_THROUGHPUT, 1, self.prefix, tags)
            if latency >= 0:
                metrics.emit_timer(_LATENCY, latency, self.prefix, tags)
        else:
            metrics.emit_counter(_ERROR, 1, self.prefix, tags)
            if latency >= 0:
                metrics.emit_timer(_LATENCY, latency, self.prefix, tags)
        if bytes_written > 0:
            metrics.emit_counter(_BYTES_WRITTEN, bytes_written, self.prefix, tags)
        if bytes_read > 0:
            metrics.emit_counter(_BYTES_READ, bytes_read, self.prefix, tags)

    def add_hit_miss_metrics(self, cmd, hits, misses, backend=None):
        tags = self.get_tags(cmd, backend)
        if hits > 0:
            metrics.emit_counter(_HIT, hits, self.prefix, tags)
        if misses > 0:
            metrics.emit_counter(_MISS, misses, self.prefix, tags)

    def add_batch_num_metrics(self, cmd, batch_num, split_count):
        tags = self.get_tags(cmd)
        metrics.emit_timer(_BATCH_NUM, batch_num, self.prefix, tags)
        if split_count > 0:
            metrics.emit_counter(_SPLIT_COUNT, split_count, self.prefix, tags)

class NullMetrics(object):
    def __init__(self, *args, **kwargs):
        pass

    def process(self, *k, **a):
        pass

    def __getattr__(self, cmd):
        return self.process

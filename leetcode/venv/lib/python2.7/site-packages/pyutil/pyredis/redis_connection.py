#!/usr/bin/env python
# -*- coding : utf8 -*-
import time
import redis
import logging
import random
import threading
import string
import copy
from conf_discover import get_cluster_servers,update_cluster_servers

UPDATE_SERVER_INTERVAL = 60
OFFLINE_APPROVE = UPDATE_SERVER_INTERVAL * 3

class ServStatus(object):
    def __init__(self, serv, **kwargs):
        self.serv = serv                #server ip:port
        self.offline = False            #offline or not
        self.dead = False               #dead sign
        self.count = 0                  #error count in 1s
        self.time = int(time.time())    #dead-time or retry-time
        self.checktime = int(time.time())   #check pool time
        host, port = serv.split(':')
        kwargs['host'] = host
        kwargs['port'] = int(port)
        self.conns = redis.ConnectionPool(**kwargs)   #connection pool 

    def is_offline(self):
        return self.offline

class MultiServConnectionPool():
    def __init__(self, servers, mark_dead_qps=3,dead_retry_interval=3, check_pool_interval=50, **kwargs):
        if 'socket_timeout' not in kwargs:
            kwargs['socket_timeout'] = 0.25
        if 'socket_connect_timeout' not in kwargs:
            kwargs['socket_connect_timeout'] = 0.05
        self.lock = threading.RLock()
        self.servlist = servers         #online server(ip:port) list (from consul)
        self.auto_update_serv = True
        self.mark_dead_qps = mark_dead_qps
        self.dead_retry_interval = dead_retry_interval
        self.check_pool_interval = check_pool_interval
        self.servs = {}                 #KV: server -> server_status
        for i in servers:
            self.servs[i] = ServStatus(i, **kwargs)
        self.dead_servs = set()         #dead server(ip:port) set
        self.alive_servs = servers           #alive server(ip:port) list (online && alive)

    def __repr__(self):
        return "%s<%s>" % (type(self).__name__, str(self.servlist))

    #offline -> online or online -> offline
    def update_servers(self, servs):
        if not self.auto_update_serv:
            return
        newservs = set(servs)
        min_cnt = 100000000
        max_cnt = 0
        if len(newservs) == 0:
            logging.warn('get none server from consul')
            return
        with self.lock:
            self.servlist = servs[:]
            for s, st in self.servs.iteritems():
                if st.offline and len(st.conns._in_use_connections) == 0:
                    #release connectionpool in offline server
                    st.conns.disconnect()
                    st.conns.reset()
                offline = s not in newservs
                if offline and not st.offline:
                    #online -> offline
                    st.time = int(time.time())
                    if st.serv in self.alive_servs:
                        self.alive_servs.remove(st.serv)
                        logging.debug('[mark offline] alive servs remove serv(%s)' % st.serv)
                    logging.warn('mark redis serv(%s) offline' % s)
                if st.offline and not offline:
                    #offline -> online
                    self.dead_servs.add(s)
                    logging.warn('mark redis serv(%s) online' % s)
                st.offline = offline

            for s in newservs:
                if s not in self.servs:
                    #new server
                    self.servs[s] = ServStatus(s)
                    if s not in self.alive_servs:
                        self.alive_servs.append(s)
                        logging.debug('[new server] alive servs add serv(%s)' % s)
                    logging.warn('add redis serv(%s)' % s)
    
    def check_dead(self, command_name):
        now = int(time.time())
        offlines = []
        dead_servs_copy = copy.deepcopy(self.dead_servs)
        for i in dead_servs_copy:
            #check server in dead_servs, dead -> ok, offline -> remove 
            st = self.servs[i]
            if st.is_offline():
                offlines.append(i)
                continue
            if st.time + self.dead_retry_interval < now:
                st.time = now
                try:
                    c = st.conns.get_connection(command_name, None)
                    conn_timeout = c.socket_connect_timeout
                except Exception as excp:
                    logging.warn('check dead_serv(%s) get connection error(%s)' % (i, excp))
                    continue
                try:
                    c.socket_connect_timeout = 0.005
                    c.connect()
                    st.dead = False
                    st.count = 0
                    self.dead_servs.remove(i)
                    if i not in self.alive_servs:
                        self.alive_servs.append(i)
                        logging.debug('[mark alive] alive servs add serv(%s)' % i)
                    logging.warn('mark redis serv(%s) alive' % i)
                except:
                    logging.warn('check dead_serv(%s) disconnection created_connection(%d)' % (i, st.conns._created_connections))
                finally:
                    c.socket_connect_timeout = conn_timeout
                    st.conns.release(c)
        for i in offlines:
            self.dead_servs.remove(i)

    def check_server(self, server, command_name):
        now = int(time.time())
        serv = self.servs[server]
        if serv.checktime + self.check_pool_interval < now:
            serv.checktime = now
            if len(serv.conns._available_connections) > 5:
                conn = serv.conns.get_connection(command_name, None)
                conn.disconnect()
                serv.conns._in_use_connections.remove(conn)
                serv.conns._created_connections -= 1
                logging.info('disconnect one connect from server(%s) free_conn_num(%d)' % (server, len(serv.conns._available_connections)))

    def get_connection(self, command_name, *keys, **options):
        get_server = False
        with self.lock:
            self.check_dead(command_name)
            alive_servs_copy = copy.deepcopy(self.alive_servs)
            for i in xrange(0, len(alive_servs_copy)):
                idx = random.randint(0, len(self.alive_servs) - 1)
                server = self.alive_servs[idx]
                if not self.servs[server].dead and not self.servs[server].offline:
                    get_server = True
                    break
                else:
                    self.alive_servs.remove(server)
                    logging.warn('[dead or offline] alive servs remove serv(%s)' % server)
            if get_server:
                self.check_server(server, command_name)
                c = self.servs[server].conns.get_connection(command_name, *keys, **options)
                logging.debug('redis get_connection use serv(%s) count:%d in_use:%d free:%d dead:%d offline:%d' 
                % (server, self.servs[server].conns._created_connections, len(self.servs[server].conns._in_use_connections), 
                len(self.servs[server].conns._available_connections), self.servs[server].dead, self.servs[server].offline))
                return c
            else:
                logging.error('redis get_connection error, all servers dead')
                return

    def mark_dead(self, conn):
        serv = '%s:%d' % (conn.host, conn.port)
        with self.lock:
            st = self.servs[serv]
            if not st.dead:
                now = int(time.time())
                if st.time == now:
                    st.count += 1
                else:
                    st.count = 1
                    st.time = now
                if st.count >= self.mark_dead_qps:
                    self.servs[serv].conns.disconnect()
                    self.servs[serv].conns.reset()
                    st.dead = True
                    self.dead_servs.add(serv)
                    if serv in self.alive_servs:
                        self.alive_servs.remove(serv)
                        logging.debug('[mark dead] alive servs remove serv(%s)' % serv)
                    logging.warn('mark redis serv(%s) dead' % serv)

    def release(self, conn):
        serv = '%s:%d' % (conn.host, conn.port)
        with self.lock:
                self.servs[serv].conns.release(conn)

class ClusterPool:
    clusters = {}
    pools = {}
    lock = threading.RLock()
    updateTask = None

    def __init__(self, cluster):
        self.cluster = cluster
        self.servers = None
        self.pools = []
        self.lock = threading.RLock()

    def append_pool(self, p):
        with self.lock:
            self.pools.append(p)

    def get_servers(self):
        with self.lock:
            if self.servers:
                return self.servers[:]
            servs = get_cluster_servers(self.cluster)
            servs.sort()
            self.servers = servs[:]
            return servs

    def update_servers(self):
        servs = update_cluster_servers(self.cluster)
        try:
            servs.remove('')
        except:
            pass
        if not servs:
            return
        servs.sort()
        with self.lock:
            if string.find(str(servs), 'consul') != -1:
                logging.warn('cluster(%s) get consul error consul(%s)' % (self.cluster, servs))
                return
            if str(self.servers) == str(servs):
                #logging.info('cluster(%s) no need to update servers old(%s) new(%s)' % (self.cluster, self.servers, servs))
                return
            logging.info('cluster(%s) update servers old(%s) new(%s)' % (self.cluster, self.servers, servs))
            self.servers = servs
            for p in self.pools:
                p.update_servers(servs)


    @classmethod
    def get_pool(cls, cluster, servers = None, **kwargs):
        with cls.lock:
            if cls.updateTask == None:
                cls.start_update_task()

            servs = servers
            if servs != None:
                servs.sort()
            k = unicode((cluster, servs, kwargs))
            if k in cls.pools:
                return cls.pools[k]
            cp = cls.clusters.get(cluster, None)
            if not cp:
                cp = ClusterPool(cluster)
                cls.clusters[cluster] = cp
            if servs:
                p = MultiServConnectionPool(servs, **kwargs)
                p.auto_update_serv = False
                cp.append_pool(p)
                cls.pools[k] = p
                return p
            servs = cp.get_servers()
            logging.info('cluster(%s) get servers(%s)' % (cluster, servs))
            p = MultiServConnectionPool(servs, **kwargs)
            p.auto_update_serv = True
            cp.append_pool(p)
            cls.pools[k] = p
            return p

    @classmethod
    def start_update_task(cls):
        def task(arg):
            arg.update_server_task()
        cls.updateTask = threading.Thread(target=task, args=(cls,))
        cls.updateTask.setDaemon(True)
        cls.updateTask.start()

    @classmethod
    def update_server_task(cls):
        while True:
            cps = []
            with cls.lock:
                for k, cp in cls.clusters.iteritems():
                    cps.append(cp)
            for cp in cps:
                try:
                    cp.update_servers()
                except Exception as excp:
                    logging.error('update_servers error cluster(%s) err(%s)' % (cp.cluster, excp))
            time.sleep(UPDATE_SERVER_INTERVAL)
            #time.sleep(300)

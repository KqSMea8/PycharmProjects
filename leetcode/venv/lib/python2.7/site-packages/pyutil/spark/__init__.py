#!/usr/bin/python
SCALA_UDF_DEF = [
    ("loadJsonToMap", "jsonToMap", "VectorOperations"),
    ("loadJsonToKVTuple", "jsonToKVTuple", "VectorOperations"),
    ("mapToLongVector", "mapToLongVector", "VectorOperations"),
    ("kvTupleToLongVector", "kvTupleToLongVector", "VectorOperations"),
    ("kvTupleToDoubleVector", "kvTupleToDoubleVector", "DoubleVectorOperations"),
    ("pythonKvTupleToLongVector", "pythonKvTupleToLongVector", "VectorOperations"),
    ("subKey", "subKey", "VectorOperations"),
    ("vectorSumByKey", "sumByKey", "VectorOperations"),
    ("vectorSumByKeyDouble", "sumByKeyDouble", "DoubleVectorOperations"),
    ("vectorColumnarizeByKey", "columnarizeByKey", "VectorOperations"),
    ("vectorColumnarizeByKeyDouble", "columnarizeByKeyDouble", "DoubleVectorOperations"),
    ("splitByField", "splitByField", "VectorOperations"),
    ("reduceByKeyPartialOrderWithPlus", "reduceByKeyPartialOrderWithPlus", "VectorOperations"),
    ("toPython", "toPython", "VectorOperations"),
    ("toJava", "toJava", "VectorOperations")
]

def handle_udf(udf_def):
    callsite_name, method_name, method_class = udf_def
    def udf(self, *args):
        from pyspark.rdd import RDD
        v = getattr(self.ctx._jvm, method_class)()
        f = getattr(v, method_name)
        return RDD(f(self._jrdd.rdd(), *args), self.ctx, self.ctx.serializer)
    return udf

def setup_udf():
    from pyspark.rdd import RDD
    for udf_def in SCALA_UDF_DEF:
        callsite_name, _, _ = udf_def
        setattr(RDD, callsite_name, handle_udf(udf_def))

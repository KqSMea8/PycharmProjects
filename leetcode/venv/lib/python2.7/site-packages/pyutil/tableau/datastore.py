#!/usr/bin/python
#coding: utf-8
import sys
import copy
from datetime import datetime as dt
from pyutil.program.conf import Conf
from pyutil.program.db import DAL

class TableauDatastore(object):
    def __init__(self, department, datastore_name):
        self.department = department
        self.datastore_name = datastore_name

        self._db_confs = self._get_db_confs()
        self._dal = self._get_db_dal()
        self._schema = self._get_table_schema() 

    def _schema_rectify(self, schema, fields):
        tmp_fields = copy.deepcopy(fields)
        for k, v in schema.items():
            if k in tmp_fields.keys() and v:
                try:
                    tmp_fields[k] = v(tmp_fields[k])
                except:
                    continue
        return tmp_fields

    def put_data_new(self, data, datetime, overwrite=True, batch_size=50):
        if overwrite:
            self.clear_data(datetime)

        columns = ["`{}`".format(name.strip("`")) for name in data[0]]
        columns.append("`datetime`")
        placeholders_list = list()
        value_statement_list = list()
        idx = 0
        while idx < len(data):
            all_fields = data[idx]
            values = []
            conds = {'datetime': datetime}
            for name in columns[:-1]:
                if name.strip('`') not in all_fields:
                    values.append('""')
                    continue
                value = all_fields[name.strip('`')]
                if isinstance(value, basestring) == True \
                   and isinstance(value, unicode) == False:
                    end_value = '"%s"' % value.decode('utf8')
                elif isinstance(value, basestring):
                    end_value = '"%s"' % value
                else:
                    end_value = value
                values.append(end_value)
            values.append("{}".format(datetime))
            placeholders_list.append("(" + ','.join(['%s']*len(values)) + ")")
            value_statement_list += values
            if len(placeholders_list) == batch_size:
                self.batch_insert_data(columns, placeholders_list, value_statement_list)
                placeholders_list = list()
                value_statement_list = list()
            idx = idx + 1
        if placeholders_list:
            self.batch_insert_data(columns, placeholders_list, value_statement_list)

    def put_data(self, datetime, metrics, dimensions=None, overwrite=False, incremental=False, rectify=False):
        datetime, _metrics, _dimensions, all_fields = self._parse_params(datetime, metrics, dimensions)
        if self._schema is None:
            self._create_table(all_fields)

        if rectify:
            all_fields = self._schema_rectify(self._schema, all_fields)
            _dimensions = self._schema_rectify(self._schema, _dimensions)

        new_columns = {k: v for k, v in all_fields.iteritems() if k not in self._schema}
        if new_columns:
            self._add_table_columns(new_columns)

        if overwrite:
            self.clear_data(datetime, _dimensions)

        if self.get_data(datetime, _dimensions):
            if incremental:
                self.increase_data(datetime, _metrics, _dimensions)
            else:
                self.update_data(datetime, _metrics, _dimensions)
        else:
            self.insert_data(datetime, all_fields)

    def insert_data(self, datetime, all_fields):
        columns = []
        values = []

        fields = {'datetime': datetime}
        fields.update(all_fields)
        conds = {'datetime': datetime}
        for name, value in fields.iteritems():
            columns.append("`{}`".format(name.strip("`")))
            if isinstance(value, basestring) == True \
               and isinstance(value, unicode) == False:
                end_value = '"%s"' % value.decode('utf8')
            elif isinstance(value, basestring):
                end_value = '"%s"' % value
            else:
                end_value = value
            values.append(end_value)
            
        placeholders = ','.join(['%s']*len(values))
        columns = ','.join(columns)
        sql_pattern = "INSERT INTO `{table_name}`({columns}) values({placeholders})".format(table_name=self.datastore_name, columns=columns, placeholders=placeholders)
        sql = sql_pattern % (tuple(values))
        self._dal.execute(sql)

    def batch_insert_data(self, columns, placeholders_list, value_statement_list):
        columns = ','.join(columns)
        sql_pattern = "INSERT INTO `{table_name}`({columns}) values {placeholders}".format(
                table_name=self.datastore_name,
                columns=columns,
                placeholders=','.join(placeholders_list))
        sql = sql_pattern % (tuple(value_statement_list))
        self._dal.execute(sql)


    def exists(self, datetime):
        sql = "select * from `%s` where datetime='%s' limit 1" % (self.datastore_name, datetime)
        self._dal.execute(sql)
        ret = self._dal.cursor.fetchall()
        return True if len(ret) > 0 else False

    def get_data(self, datetime, dimensions=None):
        datetime, _, _dimensions, _ = self._parse_params(datetime, dimensions=dimensions)
        conds = {'datetime': datetime}
        conds.update(_dimensions)
        conds = ["`%s`=%s" % (k, isinstance(v, basestring) and '"%s"' % v or v) for k, v in conds.iteritems()]
        sql = "select * from `%s` where %s" % (self.datastore_name, ' and '.join(conds))
        self._dal.execute(sql)
        ret = self._dal.cursor.fetchall()
        return ret

    def update_data(self, datetime, metrics, dimensions=None):
        datetime, _, _dimensions, _ = self._parse_params(datetime, dimensions=dimensions)
        _dimensions.update({'datetime': datetime})
        conds = ["`%s`=%s" % (k, isinstance(v, basestring) and '"%s"' % v.replace("'", "\\'") or v) for k, v in _dimensions.iteritems()]
        measures = ["`%s`=%s" % (k, isinstance(v, basestring) and '"%s"' % v.replace("'", "\\'") or v) for k, v in metrics.iteritems()]
        sql = "UPDATE `%s` set %s where %s" % (self.datastore_name, ','.join(measures), ' and '.join(conds))
        self._dal.execute(sql)

    def increase_data(self, datetime, metrics, dimensions=None):
        '''
        只支持数值型字段的累加，若metrics中包括非数值类型则报错。
        SQL : UPDATE table SET a = a + 5 WHERE id = 1
        '''

        from numbers import Number
        for v in metrics.values():
            if not isinstance(v, Number):
                raise Exception('increase_data 只支持数值型字段的累加')

        datetime, _, _dimensions, _ = self._parse_params(datetime, dimensions=dimensions)
        _dimensions.update({'datetime': datetime})
        conds = ["`%s`=%s" % (k, isinstance(v, basestring) and '"%s"' % v.replace("'", "\\'") or v) for k, v in _dimensions.iteritems()]
        measures = ["`%s`=`%s`+%s" % (k, k, v) for k, v in metrics.iteritems()]
        sql = "UPDATE `%s` set %s where %s" % (self.datastore_name, ','.join(measures), ' and '.join(conds))
        self._dal.execute(sql)

    def clear_data(self, datetime, dimensions=None):
        datetime, _, _dimensions, _ = self._parse_params(datetime, dimensions=dimensions)
        columns = ['`datetime`=%s']
        values = [datetime]
        for name, value in _dimensions.iteritems():
            columns.append("`{}`=%s".format(name))
            values.append(value)
        sql = "DELETE FROM `{table_name}` where {conds}".format(table_name=self.datastore_name, conds=' and '.join(columns))
        self._dal.execute(sql, *values)

    def get_departments(self):
        return self._db_confs.keys()

    def _get_db_confs(self):
        confs = Conf('/opt/tiger/ss_conf/ss/db_tableau.conf').get_all()
        departments = {name.split('_')[1] for name in confs if name.startswith('tableau_')}
        departments = {name[:-2] for name in departments if name.endswith('db')}
        if self.department not in departments:
            raise Exception("Department [{}] not supported, available: [{}]".format(self.department, ','.join(departments)))

        db_confs = {}
        for department in departments:
            db_confs[department] = {
                'host': confs["tableau_{}db_write_host".format(department)],
                'port': confs["tableau_{}db_write_port".format(department)],
                'user': confs["tableau_{}db_write_user".format(department)],
                'passwd': confs["tableau_{}db_write_password".format(department)],
                'name': confs["tableau_{}db_name".format(department)],
            }
        return db_confs

    def _get_db_dal(self):
        conf = self._db_confs[self.department]
        conf["connect_timeout"] = 5
        conf["read_timeout"] = 60
        return DAL(**conf)

    def _get_table_schema(self):
        tables = {row.values()[0].encode('utf-8') for row in self._dal.execute("SHOW TABLES")}
        if self.datastore_name not in tables:
            return None

        schema = {}
        for row in self._dal.execute("DESC `{}`".format(self.datastore_name)):
            field_name = row['Field'].encode('utf-8')
            field_type = row['Type'].encode('utf-8')
            schema[field_name] = self._type_db2py(field_type)
        return schema

    def _type_db2py(self, db_type):
        if 'int' in db_type:
            return int
        elif 'char' in db_type:
            return str
        elif 'double' in db_type:
            return float

    def _type_py2db(self, py_type):
        mapping = {
            long: 'bigint(20) NOT NULL DEFAULT 0',
            int: 'int(11) NOT NULL DEFAULT 0',
            str: 'varchar(32) NOT NULL DEFAULT ""',
            unicode: 'varchar(32) NOT NULL DEFAULT ""',
            float: 'decimal(10, 4) NOT NULL DEFAULT "0.00"',
        }
        if py_type not in mapping.keys():
            raise Exception("Data type [{}] not supported, available: {}".format(py_type, map(str, mapping.keys())))
        return mapping[py_type]

    def _parse_params(self, datetime, metrics=None, dimensions=None):
        datetime = isinstance(datetime, dt) and datetime.strftime('%Y%m%d') or datetime
        _metrics = metrics and copy.copy(metrics) or {}
        _dimensions = dimensions and copy.copy(dimensions) or {}

        all_fields = {}
        if datetime:
            all_fields.update({'datetime': datetime})

        if _dimensions:
            fields = set(all_fields.keys()) & set(_dimensions.keys())
            if fields:
                raise Exception("Field {} conflicted".format(list(fields)))
            all_fields.update(_dimensions)

        if _metrics:
            fields = set(all_fields.keys()) & set(_metrics.keys())
            if fields:
                raise Exception("Field {} conflicted".format(list(fields)))
            all_fields.update(_metrics)

        return datetime, _metrics, _dimensions, all_fields

    def _create_table(self, fields):
        sql_pattern = """
        CREATE TABLE `{table_name}`(
        `id` int(11) NOT NULL AUTO_INCREMENT,
        {columns},
        PRIMARY KEY (`id`),
        INDEX `idx_datetime` (`datetime`)
        ) ENGINE=InnoDB AUTO_INCREMENT=108 DEFAULT CHARSET=utf8;
        """
        columns = ["`{}` {}".format(name, self._type_py2db(type(value))) for name, value in fields.iteritems()]
        sql = sql_pattern.format(table_name=self.datastore_name, columns=',\n'.join(columns))
        self._dal.execute(sql)
        self._schema = self._get_table_schema()

    def _add_table_columns(self, fields):
        sql_pattern="""ALTER TABLE `{table_name}` ADD COLUMN  `{column_name}`  {type}"""
        sql = ''
        for column_name, value in fields.iteritems():
            try:
                db_type = self._type_py2db(type(value))
                sql = sql_pattern.format(table_name=self.datastore_name, column_name=column_name, type=db_type)
                self._dal.execute(sql)
            except Exception as e:
                raise Exception('sql: {}, exception: {}'.format(sql, e))

        self._schema = self._get_table_schema()

if __name__ == '__main__':
    lines = [
        {u'gid': u'1537452127938562', u'g_type': u'4', u'g_cat': 'news'},
        {u'gid': u'1561484194363393', u'g_type': u'4', u'g_cat': 'news_agriculture'},
        {u'gid': u'1560830535924737', u'g_type': u'4', u'g_cat': 'news_travel'},
        ]
    tableau = TableauDatastore('data', 'video_all')
    tableau.put_data_new(data=lines, datetime="20170313", overwrite=True)
    print tableau.exists('20161212')
    td = TableauDatastore('growth', 'news_article_retention_channel_version2')
    datetime = 1463932800 
    metrics = {u'new_user_retention': 0.23076923076923078, u'activation': 13, u'dau_retention': 0.7875739644970414, u'dau': 1690}
    dimensions = {u'app_version': u'5.4.5', u'os': u'android', u'app_name': u'news_article', u'datekey': 20160522, u'channel': '360ffff'}
    td.put_data(datetime, metrics, dimensions, rectify=True)
    metrics = {u'new_user_retention': 0.23076923076923078, u'activation': 13, u'dau_retention': 0.7875739644970414, u'dau': 1690}
    dimensions = {u'app_version': u'5.4.5', u'os': u'android', u'app_name': u'news_article', u'datekey': 20160522, u'channel': '360ff'}
    td.put_data(datetime, metrics, dimensions, rectify=True)
    metrics = {u'new_user_retention': 0.23076923076923078, u'activation': 13, u'dau_retention': 0.7875739644970414, u'dau': 1690}
    dimensions = {u'app_version': u'5.4.5', u'os': u'android', u'app_name': u'news_article', u'datekey': 20160522, u'channel': '360xy'}
    td.put_data(datetime, metrics, dimensions, rectify=True)
    metrics = {u'new_user_retention': 0.23076923076923078, u'activation': 13, u'dau_retention': 0.7875739644970414, u'dau': 1690}
    dimensions = {u'app_version': u'5.4.5', u'os': u'android', u'app_name': u'news_article', u'datekey': 20160522, u'channel': 360}
    td.put_data(datetime, metrics, dimensions, rectify=True)

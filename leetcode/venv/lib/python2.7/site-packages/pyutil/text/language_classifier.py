#!/usr/bin/env python
#coding=utf-8

import cld, logging, re, codecs, os
from sets import Set

language_map = {'Chinese':'chinese', 'Chinese_Mixture':'chinese_mix', 'ENGLISH':'english', 'ChineseT':'chinese_tw', 'Japanese':'japanese', 'Korean':'korean', 'Other':'other', 'Unreliable':'unreliable'}

traditional_character_set = Set()
with codecs.open(os.path.dirname(os.path.abspath(__file__)) + '/jian2fan.txt', mode='rb', encoding='utf-8') as file:
    traditional_character_set = Set([line[0:-1].split()[1] for line in file])

def classify_message_simple(message_text):
    '''
    References:
    1. http://blog.csdn.net/shuilan0066/article/details/7839189
    2. http://thoughtfly.iteye.com/blog/977478
    '''
    if not message_text:
        return 'unknown'

    clean_message_text = _get_clean_text_from_html(message_text)
    if not clean_message_text:
        return 'unknown'
    clean_message_text = ''.join(clean_message_text.split())
    #logging.info('clean_message_text: %s', clean_message_text)

    chinese_count = 0
    traditional_count = 0
    english_count = 0
    digit_count = 0
    other_ascii_count = 0
    other_none_ascii_count = 0
    for word in clean_message_text:
        if word in traditional_character_set:
            traditional_count += 1
        elif word >= '0' and word <= '9':
            digit_count += 1
        elif (word >= 'a' and word <= 'z') or (word >= 'A' and word <= 'Z'):
            english_count += 1
        elif word < 256:
            other_ascii_count += 1
        elif word >= u'\u4e00'  and word < u'\u9FFF':
            chinese_count += 1
        else:
            other_none_ascii_count += 1

    digit_word_count = digit_count / 3
    english_word_count = english_count / 5
    total_count = digit_word_count + english_word_count + chinese_count + traditional_count + other_ascii_count + other_none_ascii_count

    count_stats = dict(
            chinese_count=chinese_count,
            traditional_count=traditional_count,
            english_word_count=english_word_count,
            digit_word_count=digit_word_count,
            other_ascii_count=other_ascii_count,
            other_none_ascii_count=other_none_ascii_count,
            )
    language = 'unknown'
    if chinese_count >= total_count * 0.7:
        language = 'chinese'
    elif traditional_count >= total_count * 0.7:
        language = 'chinese_tw'
    elif  english_word_count >= total_count * 0.7:
        language = 'english'
    elif (chinese_count + english_word_count) >= total_count * 0.7:
        language = 'chinese_mix'
    elif (chinese_count + traditional_count) >= total_count * 0.7:
        language = 'chinese_tw'
#    elif (english_word_count + traditional_count) >= total_count * 0.8:
#        return 'chinese_mix'
    else:
        language = 'unknown'

    logging.debug('language=%s (%s)', language,
            ' '.join('%s=%s' % x for x in count_stats.items())
            )

    return language

def _get_clean_text_from_html(body):
    import lxml
    from lxml.html.clean import Cleaner
    from lxml import html
    from lxml import etree
    cleaner = lxml.html.clean.Cleaner()

    cleaner.javascript = True  # This is True because we want to activate the javascript filter
    cleaner.style = True  # This is True because we want to activate the styles & stylesheet filter

    # Remove declaration like '<?xml version="1.0" encoding="utf-8"?>', since if it is present, the encoding of the parameter of clean_html must be consistent for
    # compatible, which will cause tradional Chinese fail.
    xml_decal_pattern = re.compile(r'<\?xml [^?]*\?>', re.UNICODE)
    body = xml_decal_pattern.sub('', body)

    clean_html = cleaner.clean_html(body)

    if not clean_html:
        return None

    parser = html.HTMLParser(recover=True)
    doc = etree.fromstring(clean_html, parser=parser)

    # doc = html.fromstring(cleaner.clean_html(body.encode('utf8')).decode('utf8'))
    clean_text = html.tostring(doc, pretty_print=False, include_meta_content_type=False, encoding=unicode, method='text')

    return clean_text

def remove_noise(message_text):
    # remove '&nbsp', it could not be handled correctly in cld, since it is not '&nbsp;'
    #text = message_text.replace('&nbsp', ' ')
    text = message_text.replace('&', ' ')
    # remove newline character inside the abstract
    text = ' '.join(text.split())
    return text

def verify_chinese_dominant(details):
    langDict = {}
    for langName, langCode, percentage, certainty in details:
        langDict[langName] = percentage
    if 'Chinese' not in langDict:
        return False

    if langDict['Chinese'] < 80:
        return False

    for key in langDict.keys():
        if key not in ['Chinese', 'ChineseT', 'ENGLISH']:
            if langDict[key] > 10:
                return False
    return True

# entry function to identify the language of a message
# input is raw html text
# output is the detection result, could be:
# Chinese, ChineseT, ENGLISH, Japanese, Korean, Chinese_Mixture, Other, Unreliable
# Chinese_Mixture means though the message mainly composed by Chinese, but contain too much other language element
# Other means language besides Chinese, ChineseT, ENGLISH, Japanese, Korean
# Unreliable means the function fails to detect dominant language
def classify_message(message_text):
    if not message_text:
        return language_map['Unreliable']

    text = remove_noise(message_text)
    try:
        detectedLangName, detectedLangCode, isReliable, textBytesFound, details = cld.detect(text.encode('utf8'), isPlainText=False, includeExtendedLanguages=True, hintTopLevelDomain=None, hintLanguageCode='zh', pickSummaryLanguage=True, removeWeakMatches=False)
        if isReliable:
            if detectedLangName == 'Chinese':
                if verify_chinese_dominant(details):
                    return language_map[detectedLangName]
                else:
                    return language_map['Chinese_Mixture']
            elif detectedLangName in ['ChineseT', 'ENGLISH', 'Japanese', 'Korean']:
                return language_map[detectedLangName]
            else:
                return language_map['Other']
        else:
            return language_map['Unreliable']
    except:
        logging.exception('classify message failed, message', message_text if message_text else 'NoneType')
        return language_map['Unreliable']

# Similar with classify_message, but give more information use format:
# detectedLangName, detectedLangCode, isReliable, textBytesFound, details
# A sample result should like:
# Chinese zh True 2353 [('Chinese', 'zh', 76, 3543.0), ('Ignore', 'xxx', 23, 196.0), ('FRENCH', 'fr', 0, 6.166495375128469)]
def classify_message_detail(message_text):
    if not message_text:
        return language_map['Unreliable'], None, None, None

    text = remove_noise(message_text)

    detectedLangName, detectedLangCode, isReliable, textBytesFound, details = cld.detect(text.encode('utf8'), isPlainText=False, includeExtendedLanguages=True, hintTopLevelDomain=None, hintLanguageCode='zh', pickSummaryLanguage=True, removeWeakMatches=False)
    if isReliable:
        if detectedLangName == 'Chinese':
            if verify_chinese_dominant(details):
                return detectedLangName, detectedLangCode, isReliable, textBytesFound, details
            else:
                return 'Mixture', detectedLangCode, isReliable, textBytesFound, details
        elif detectedLangName in ['ChineseT', 'ENGLISH', 'Japanese', 'Korean']:
            return detectedLangName, detectedLangCode, isReliable, textBytesFound, details
        else:
            return 'Other', detectedLangCode, isReliable, textBytesFound, details
    else:
        return 'Unreliable', detectedLangCode, isReliable, textBytesFound, details


def main():
    message1 = u'<p><br><img src="{{image_domain}}{"width": 372, "uri": "1605/5208128777", "height": 518}">\
    <br></p><p>今天簡直是WP8的宇宙大爆發！除了Evleaks的爆料及HTC的WP8外，現在還來了數張疑似Nokia Lumia 820 的工程機實機照！</p><p>由以\
    下的圖片中，我們可以看到這部疑以Nokia Lumia 820的手機運行WP8 ，RAM為335MB，可見屬中低階的Lumia WP8。手機採用圓角設計，與早前的Nokia Arrow\
    特徵相乎。WP三鍵方面，這部疑似Nokia Lumia 820使用了電容式按鈕，與Nokia Arrow的流出前方面版亦相乎。另外，大家可以看到，白色的機身上寫著\
    proto.nokia.com」，可見此手機為工程機。與剛才由Evleaks流出的圖片看來，這部工程機的背面與圖片有少許不同，或者與工程機有關。\
    </p><p><br><img src="{{image_domain}}{"width": 447, "uri": "1605/5208202644", "height": 518}">\
    <br></p><p><br><img src="{{image_domain}}{"width": 406, "uri": "1605/5208252387", "height": 498}">\
    <br></p><p><br><img src="{{image_domain}}{"width": 392, "uri": "1605/5208305422", "height": 519}"><br></p><p>\
    這些清晰的相片，看來相當可靠！不知各位讀者又有何看法？</p><p>網站管理員暨編輯。醫管局下一個小小的實習醫生。文筆不好，但卻喜愛與所有讀者分享有關Windows Phone的\
    趣聞。酷愛WP帶給自己的方便，更期待WP將來與Windows 8互相帶來的火花。用過Symbian、iOS、Android及年代久遠的Windows Mobile，還是覺得WP最適合自己。\
    曾使用的WP包括HTC HD7、LG Optimus 7、HTC Radar、Acer Allegro、Nokia Lumia 800及Nokia Lumia 710。現役WP為Nokia Lumia 900，\
    後備WP為HTC HD7，將在WP8推出後盡快入手第三代WP！</p>'
    message1 = u'2日下午，在招行官网可下载区的名单上，最后一栏居然出现"备注"，内容写着“某某行长亲戚关系、银监局某领导关系、客户关系等”。据了解的确为招行员工误将"内部资料"上传到官网。但目前该资料已被删除。相关负责人表示，此事目前还在'
    detectedLangName = classify_message_simple(message1)
    print detectedLangName
    return

    detectedLangName = classify_message(message1)
    print detectedLangName

    detectedLangName, detectedLangCode, isReliable, textBytesFound, details = classify_message_detail(message1)
    print detectedLangName, detectedLangCode, isReliable, textBytesFound, details

if __name__ == '__main__':
    main()
